{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0271977d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## packages\n",
    "import os\n",
    "import sys\n",
    "# get parent dir\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname('USskintumor'))))\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "import flask\n",
    "from flask import Flask, request, render_template\n",
    "\n",
    "import numpy as np\n",
    "from scipy import misc\n",
    "import imageio\n",
    "import copy\n",
    "\n",
    "from model.combined_CNN_for_CAM import conv3x3, combined_cnn, _combined_model\n",
    "from loss_functions.focal_loss import  *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6445dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CUDA\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    raise Exception('cuda is not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e95635fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## model define, transform\n",
    "def combined_net(**kwargs):\n",
    "    return _combined_model(transfer_learning=True, num_classes = 3,  **kwargs)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.Resize((224,224), 3),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5], [0.5])\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9523edf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## main page routing\n",
    "app = Flask(__name__)\n",
    "@app.route('/')\n",
    "@app.route('/index')\n",
    "\n",
    "def index(): # load html templates\n",
    "    return flask.render_template('index.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b660b55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## prediction protocol\n",
    "@app.route('/predict', methods=['POST'])\n",
    "\n",
    "def make_prediction():\n",
    "    class_names = {'0':'epidermal cyst', '1':'lipoma', '2':'pilomatricoma'}\n",
    "    global transform\n",
    "    '''model'''\n",
    "    model = combined_net().cuda()\n",
    "    model_path = '../final_saved/0603/focal_loss/1.pth'\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "\n",
    "    if request.method == 'POST':\n",
    "        # file upload protocol\n",
    "        file = request.files['image']\n",
    "        if not file : return render_templates('index.html', label = 'No Files')\n",
    "        filename = file.filename\n",
    "        img = imageio.imread(file)\n",
    "        original_img = copy.deepcopy(img)\n",
    "        img = cv2.resize(img, (224,224))\n",
    "        origin = copy.deepcopy(img)\n",
    "\n",
    "        '''save image'''\n",
    "        img = Image.fromarray(img)\n",
    "        img = transform(img)\n",
    "        img = img.view((1,) + img.shape)\n",
    "        model.eval()\n",
    "        '''prediction'''\n",
    "\n",
    "        output, g_att1, g_att2, x8 = model(img.cuda())\n",
    "\n",
    "        prediction = torch.where(output[0] == output.max())[0].item()\n",
    "        label = 'Predicted : ' + class_names[str(prediction)] + ' ' + '   /   Probability : ' + str(round(round(torch.softmax(output, -1)[0].max().item(), 3) * 100, 2)) + ' %'\n",
    "        \n",
    "        if not os.path.exists('./static/image/' + class_names[str(prediction)]):\n",
    "            os.makedirs('./static/image/' + class_names[str(prediction)])\n",
    "            \n",
    "        im_list = os.listdir('./static/image/' + class_names[str(prediction)])\n",
    "        file_num = int(len(im_list)/2) + 1\n",
    "        file_ex = filename[filename.index('.')+1:] # file extension\n",
    "        cv2.imwrite('./static/image/' + class_names[str(prediction)] + '/' + filename[:filename.index('.')] + '_' + str(file_num) + '.' + file_ex, original_img)\n",
    "        '''CAM image rendering'''\n",
    "        fw = model.classifier.weight.cpu().detach().numpy()\n",
    "        fw = fw.transpose()\n",
    "        fw_weights = {0:fw[0:3], 1:fw[3:6], 2:fw[6:9]}\n",
    "        \n",
    "        weights = {0: model.classifier1.weight.cpu().detach().numpy(),\n",
    "                   1: model.classifier2.weight.cpu().detach().numpy(),\n",
    "                   2: model.classifier3.weight.cpu().detach().numpy()}\n",
    "        \n",
    "        fnumbers = {0: 128, 1: 256, 2: 512}\n",
    "        fmaps = {0: g_att1.cpu().detach().numpy(),\n",
    "                      1: g_att2.cpu().detach().numpy(),\n",
    "                      2: x8.cpu().detach().numpy()}\n",
    "\n",
    "        pred = torch.softmax(output, dim=1)\n",
    "        pred_id = torch.argmax(pred).item()\n",
    "        # check among 3 classes\n",
    "        for a in range(3):\n",
    "            fn,w,fm, fw = fnumbers[a], weights[a], fmaps[a], fw_weights[a].transpose()\n",
    "            for i in range(fn):\n",
    "                # prediction : pred_id\n",
    "                if i == 0: c_cam = w[pred_id][i] * fm[0][i]\n",
    "                else: c_cam += w[pred_id][i] * fm[0][i]\n",
    "\n",
    "            c_cam * np.mean(fw[pred_id])\n",
    "            c_cam = cv2.resize(c_cam, (224,224), interpolation = cv2.INTER_CUBIC)\n",
    "            if a == 0 : whole_cam = c_cam\n",
    "            else: whole_cam += c_cam\n",
    "\n",
    "        if pred_id == 1:\n",
    "            whole_cam = whole_cam.max() - whole_cam   \n",
    "        \n",
    "        cam = whole_cam\n",
    "        x,y = np.where(cam < cam.max()*0.7)\n",
    "        cam[x,y] = cam.min()\n",
    "        # normalization to uint8\n",
    "        cam_norm = np.zeros(cam.shape, dtype = 'uint8')\n",
    "        final_cam = cv2.normalize(cam, cam_norm, 0, 255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "\n",
    "        plt.imshow(origin, cmap='gray')\n",
    "        plt.imshow(final_cam, cmap ='jet', alpha =0.4)\n",
    "        plt.axis('off')\n",
    "        '''save figure in your directory'''\n",
    "        plt.savefig('./static/image/'+ class_names[str(prediction)] +'/CAM_'+filename[:filename.index('.')]+'_'+str(file_num)+'.'+file_ex,\n",
    "                    bbox_inches = 'tight', edgecolor='black', pad_inches = 0)\n",
    "\n",
    "        return render_template('index.html', label=label,\n",
    "                               image_file='image/' + class_names[str(prediction)] + '/' + file.filename[:file.filename.index('.')] + '_' + str(file_num) + '.' + file_ex,\n",
    "                               cam_file='image/' + class_names[str(prediction)] + '/CAM_' + file.filename[:file.filename.index('.')] + '_' + str(file_num) + '.' + file_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd2c9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on all addresses.\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      " * Running on http://192.168.0.20:5000/ (Press CTRL+C to quit)\n",
      "192.168.0.20 - - [10/Nov/2021 16:57:09] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.0.20 - - [10/Nov/2021 16:57:09] \"GET /static/ HTTP/1.1\" 404 -\n",
      "192.168.0.20 - - [10/Nov/2021 16:57:09] \"GET /static/style.css HTTP/1.1\" 404 -\n",
      "Z:\\codes\\USskintumor\\model\\Gridattentionblock.py:47: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  nn.init.constant(self.psi.bias.data, 10.0) # initialize the bias for psi\n",
      "Z:\\codes\\USskintumor\\weight_inits.py:17: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  init.kaiming_normal(m.weight.data, a=0, mode='fan_in')\n",
      "D:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:2952: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "D:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:3060: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\"Default upsampling behavior when mode={} is changed \"\n",
      "D:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "192.168.0.20 - - [10/Nov/2021 16:57:15] \"POST /predict HTTP/1.1\" 200 -\n",
      "192.168.0.20 - - [10/Nov/2021 16:57:15] \"GET /static/style.css HTTP/1.1\" 404 -\n",
      "192.168.0.20 - - [10/Nov/2021 16:57:16] \"GET /static/image/lipoma/7713683_20200212163809_002_1.png HTTP/1.1\" 200 -\n",
      "192.168.0.20 - - [10/Nov/2021 16:57:16] \"GET /static/image/lipoma/CAM_7713683_20200212163809_002_1.png HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    #Flask 서비스 스타트\n",
    "    # app.run(host='192.168.0.20:3389')\n",
    "    app.run(host = '0.0.0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c9d09d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
